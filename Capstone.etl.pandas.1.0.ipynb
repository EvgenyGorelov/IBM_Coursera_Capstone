{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Advanced Data Science Capstone\n",
    "\n",
    "## Correlation of air pollution and Prevalence of Heart failures in Germany  \n",
    "\n",
    "## Data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The deliverables\n",
    "The deliverables of the current stage:\n",
    "\n",
    " - current notebook as the process documentation\n",
    " - Pandas dataframe of the \"wide\" type, containing time series of pollutants concentrations and the unique sensor ID and a county id\n",
    " - Pandas dataframe with disease prevalence column(s) (heart failures,...) and a county id\n",
    "\n",
    "### Data cleansing\n",
    " - The air quality data sets are claimed to be \"validated\", so most work for cleansing the data is already done.\n",
    " - The incomplete files from the datasets (not having \"hour\" in the name) are ignored.\n",
    " - Few missing values appearing in the time series as negative values of the pollutant concentrations will be imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re, collections\n",
    "from io import StringIO\n",
    "import os, fnmatch, fastparquet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def SelectAllXMLsensorID():\n",
    "    varFull = [s for s in AllTags if 'value' in s][0]\n",
    "    return([re.sub(r'[^a-zA-Z0-9:]*\\'{http(.*)$', r'', re.sub(r'^.*AQD\\/SPO.DE_', r'', str(varr.attrib))) for varr in Eroot.iter(varFull) if 'AQD' in str(varr.attrib)]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the files with pollutant concentration time series for the given year will be loaded to the **dffAll** Pandas dataframe of the **wide** format. During the load procedure **consistensy** of **files** and **column** names will be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the dataset 156\n"
     ]
    }
   ],
   "source": [
    "AirE1aDir='Capstone.rawData/AQD_DE_E1a_2017/'\n",
    "\n",
    "#!ls Capstone.rawData/AQD_DE_E1a_2017/*hour*\n",
    "FilesHour=[]\n",
    "\n",
    "for file in os.listdir(AirE1aDir):\n",
    "    if fnmatch.fnmatch(file, '*hour*'):\n",
    "        FilesHour.append(file)\n",
    "print(\"Number of files in the dataset\", len(FilesHour))\n",
    "\n",
    "# shortening the process for debugging purposes\n",
    "#FilesHour=FilesHour[0:3]        \n",
    "\n",
    "dffAll=pd.DataFrame(index=range(0,8760))  # 8760 hours in the year\n",
    "\n",
    "# add First column with Observation Times:\n",
    "dff=[]  # Temporary list for DataFrames\n",
    "\n",
    "file=FilesHour[0]\n",
    "Etree = ET.parse(AirE1aDir+file)\n",
    "Eroot = Etree.getroot()\n",
    "Eroot.tag\n",
    "Eroot.attrib\n",
    "AllTags = [elem.tag for elem in Eroot.iter()]\n",
    "varFull = [s for s in AllTags if 'values' in s][0]\n",
    "for varr in Eroot.iter(varFull):\n",
    "    dff.append(pd.read_csv(StringIO((varr.text).replace(\"@@\",\"\\n\")), sep=\",\", header=None))\n",
    "dffAll=pd.concat([dffAll, dff[0][[0]]], axis=1)\n",
    "dffAll.columns=['observation_period']\n",
    "\n",
    "\n",
    "# get all tags in xml file; Note, that the actual data is kept as a TEXT of *values* tags \n",
    "for file in FilesHour:\n",
    "    Etree = ET.parse(AirE1aDir+file)\n",
    "    Eroot = Etree.getroot()\n",
    "    Eroot.tag\n",
    "    Eroot.attrib\n",
    "    AllTags = [elem.tag for elem in Eroot.iter()]\n",
    "    \n",
    "    ColNamesExp=SelectAllXMLsensorID()\n",
    "# Compare column names with file names, they should encode same country, state and pollutant\n",
    "    for ColName in ColNamesExp:\n",
    "        if ((ColName[0:2]!=file[0:2]) or (ColName[2:4]!=file[3:5]) or (ColName[8:11]!=file[11:14])):\n",
    "            print(\"Inconsistency in file and column names: \", file, ColName)\n",
    "            exit()\n",
    "    \n",
    "    varFull = [s for s in AllTags if 'values' in s][0]\n",
    "    \n",
    "    dff=[] # Temporary list for DataFrames\n",
    "# reading actual pollutant data fiom the text field:    \n",
    "    for varr in Eroot.iter(varFull):\n",
    "        dff.append(pd.read_csv(StringIO((varr.text).replace(\"@@\",\"\\n\")), sep=\",\", header=None))\n",
    "\n",
    "# checking, that measurment timestamps are identical in the files read       \n",
    "    for s in range(0,len(dff)):\n",
    "        if not (dffAll['observation_period']).equals(dff[s][0]):\n",
    "            print(\"Inconsistency of observation times in the following files: \", file, FilesHour[0])\n",
    "            exit()\n",
    "\n",
    "        \n",
    "# select column 4 - pollutant concentration:\n",
    "    dff=pd.concat([dff[s][4] for s in range(0,len(dff))], axis=1)\n",
    "    dff.columns=ColNamesExp\n",
    "   \n",
    "    dffAll=pd.concat([dffAll, dff], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage:  151.5784454345703  MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESH001_O3_dataGroup1</th>\n",
       "      <th>DESH008_O3_dataGroup1</th>\n",
       "      <th>DESH013_O3_dataGroup1</th>\n",
       "      <th>DESH014_O3_dataGroup1</th>\n",
       "      <th>DESH015_O3_dataGroup1</th>\n",
       "      <th>DESH016_O3_dataGroup1</th>\n",
       "      <th>DESH023_O3_dataGroup1</th>\n",
       "      <th>DESH033_O3_dataGroup1</th>\n",
       "      <th>DESH035_O3_dataGroup1</th>\n",
       "      <th>DESH056_O3_dataGroup1</th>\n",
       "      <th>...</th>\n",
       "      <th>DEHH015_PM1_dataGroup1</th>\n",
       "      <th>DEHH016_PM1_dataGroup1</th>\n",
       "      <th>DEHH026_PM1_dataGroup1</th>\n",
       "      <th>DEHH033_PM1_dataGroup1</th>\n",
       "      <th>DEHH059_PM1_dataGroup1</th>\n",
       "      <th>DEHH068_PM1_dataGroup1</th>\n",
       "      <th>DEHH070_PM1_dataGroup1</th>\n",
       "      <th>DEHH072_PM1_dataGroup1</th>\n",
       "      <th>DEHH079_PM1_dataGroup1</th>\n",
       "      <th>DEHH081_PM1_dataGroup1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "      <td>8760.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.374908</td>\n",
       "      <td>48.709722</td>\n",
       "      <td>37.286848</td>\n",
       "      <td>60.931687</td>\n",
       "      <td>42.575316</td>\n",
       "      <td>-397.154575</td>\n",
       "      <td>39.948094</td>\n",
       "      <td>-511.639592</td>\n",
       "      <td>37.867500</td>\n",
       "      <td>-28.696564</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.273549</td>\n",
       "      <td>-8.032516</td>\n",
       "      <td>-55.883309</td>\n",
       "      <td>-12.692748</td>\n",
       "      <td>-28.061636</td>\n",
       "      <td>16.247620</td>\n",
       "      <td>3.343157</td>\n",
       "      <td>-28.703924</td>\n",
       "      <td>-0.194743</td>\n",
       "      <td>-10.264745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>50.596504</td>\n",
       "      <td>73.491147</td>\n",
       "      <td>149.589802</td>\n",
       "      <td>33.518547</td>\n",
       "      <td>85.258260</td>\n",
       "      <td>511.246865</td>\n",
       "      <td>104.336547</td>\n",
       "      <td>525.860031</td>\n",
       "      <td>70.716164</td>\n",
       "      <td>281.257366</td>\n",
       "      <td>...</td>\n",
       "      <td>211.948821</td>\n",
       "      <td>155.066454</td>\n",
       "      <td>269.333205</td>\n",
       "      <td>170.167351</td>\n",
       "      <td>208.851818</td>\n",
       "      <td>87.331396</td>\n",
       "      <td>125.651302</td>\n",
       "      <td>209.301279</td>\n",
       "      <td>139.332240</td>\n",
       "      <td>174.797689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.517250</td>\n",
       "      <td>37.534750</td>\n",
       "      <td>44.862250</td>\n",
       "      <td>46.691750</td>\n",
       "      <td>32.350750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>32.580250</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>26.056250</td>\n",
       "      <td>29.833500</td>\n",
       "      <td>...</td>\n",
       "      <td>8.667750</td>\n",
       "      <td>7.454750</td>\n",
       "      <td>10.366000</td>\n",
       "      <td>8.229000</td>\n",
       "      <td>7.656000</td>\n",
       "      <td>11.960750</td>\n",
       "      <td>10.458750</td>\n",
       "      <td>6.427250</td>\n",
       "      <td>11.132500</td>\n",
       "      <td>10.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.199500</td>\n",
       "      <td>53.988500</td>\n",
       "      <td>59.384500</td>\n",
       "      <td>65.548000</td>\n",
       "      <td>49.974000</td>\n",
       "      <td>8.216000</td>\n",
       "      <td>50.504500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>42.929000</td>\n",
       "      <td>52.865000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.801000</td>\n",
       "      <td>12.723500</td>\n",
       "      <td>16.290500</td>\n",
       "      <td>13.302000</td>\n",
       "      <td>12.888500</td>\n",
       "      <td>19.360000</td>\n",
       "      <td>15.781500</td>\n",
       "      <td>11.748500</td>\n",
       "      <td>15.707000</td>\n",
       "      <td>16.113500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.562000</td>\n",
       "      <td>68.677500</td>\n",
       "      <td>70.980000</td>\n",
       "      <td>77.226500</td>\n",
       "      <td>64.915250</td>\n",
       "      <td>41.180250</td>\n",
       "      <td>66.478000</td>\n",
       "      <td>55.730000</td>\n",
       "      <td>56.653250</td>\n",
       "      <td>68.088000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.444750</td>\n",
       "      <td>20.192750</td>\n",
       "      <td>25.062250</td>\n",
       "      <td>20.403500</td>\n",
       "      <td>20.664000</td>\n",
       "      <td>30.738000</td>\n",
       "      <td>23.237250</td>\n",
       "      <td>20.787250</td>\n",
       "      <td>22.993000</td>\n",
       "      <td>23.949250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>145.660000</td>\n",
       "      <td>131.607000</td>\n",
       "      <td>138.455000</td>\n",
       "      <td>154.401000</td>\n",
       "      <td>143.936000</td>\n",
       "      <td>142.818000</td>\n",
       "      <td>144.126000</td>\n",
       "      <td>127.519000</td>\n",
       "      <td>124.948000</td>\n",
       "      <td>132.191000</td>\n",
       "      <td>...</td>\n",
       "      <td>275.973000</td>\n",
       "      <td>190.385000</td>\n",
       "      <td>266.052000</td>\n",
       "      <td>152.603000</td>\n",
       "      <td>196.997000</td>\n",
       "      <td>469.227000</td>\n",
       "      <td>277.583000</td>\n",
       "      <td>113.427000</td>\n",
       "      <td>170.415000</td>\n",
       "      <td>537.024000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DESH001_O3_dataGroup1  DESH008_O3_dataGroup1  DESH013_O3_dataGroup1  \\\n",
       "count            8760.000000            8760.000000            8760.000000   \n",
       "mean               45.374908              48.709722              37.286848   \n",
       "std                50.596504              73.491147             149.589802   \n",
       "min              -999.000000            -999.000000            -999.000000   \n",
       "25%                29.517250              37.534750              44.862250   \n",
       "50%                48.199500              53.988500              59.384500   \n",
       "75%                64.562000              68.677500              70.980000   \n",
       "max               145.660000             131.607000             138.455000   \n",
       "\n",
       "       DESH014_O3_dataGroup1  DESH015_O3_dataGroup1  DESH016_O3_dataGroup1  \\\n",
       "count            8760.000000            8760.000000            8760.000000   \n",
       "mean               60.931687              42.575316            -397.154575   \n",
       "std                33.518547              85.258260             511.246865   \n",
       "min              -999.000000            -999.000000            -999.000000   \n",
       "25%                46.691750              32.350750            -999.000000   \n",
       "50%                65.548000              49.974000               8.216000   \n",
       "75%                77.226500              64.915250              41.180250   \n",
       "max               154.401000             143.936000             142.818000   \n",
       "\n",
       "       DESH023_O3_dataGroup1  DESH033_O3_dataGroup1  DESH035_O3_dataGroup1  \\\n",
       "count            8760.000000            8760.000000            8760.000000   \n",
       "mean               39.948094            -511.639592              37.867500   \n",
       "std               104.336547             525.860031              70.716164   \n",
       "min              -999.000000            -999.000000            -999.000000   \n",
       "25%                32.580250            -999.000000              26.056250   \n",
       "50%                50.504500            -999.000000              42.929000   \n",
       "75%                66.478000              55.730000              56.653250   \n",
       "max               144.126000             127.519000             124.948000   \n",
       "\n",
       "       DESH056_O3_dataGroup1  ...  DEHH015_PM1_dataGroup1  \\\n",
       "count            8760.000000  ...             8760.000000   \n",
       "mean              -28.696564  ...              -28.273549   \n",
       "std               281.257366  ...              211.948821   \n",
       "min              -999.000000  ...             -999.000000   \n",
       "25%                29.833500  ...                8.667750   \n",
       "50%                52.865000  ...               13.801000   \n",
       "75%                68.088000  ...               21.444750   \n",
       "max               132.191000  ...              275.973000   \n",
       "\n",
       "       DEHH016_PM1_dataGroup1  DEHH026_PM1_dataGroup1  DEHH033_PM1_dataGroup1  \\\n",
       "count             8760.000000             8760.000000             8760.000000   \n",
       "mean                -8.032516              -55.883309              -12.692748   \n",
       "std                155.066454              269.333205              170.167351   \n",
       "min               -999.000000             -999.000000             -999.000000   \n",
       "25%                  7.454750               10.366000                8.229000   \n",
       "50%                 12.723500               16.290500               13.302000   \n",
       "75%                 20.192750               25.062250               20.403500   \n",
       "max                190.385000              266.052000              152.603000   \n",
       "\n",
       "       DEHH059_PM1_dataGroup1  DEHH068_PM1_dataGroup1  DEHH070_PM1_dataGroup1  \\\n",
       "count             8760.000000             8760.000000             8760.000000   \n",
       "mean               -28.061636               16.247620                3.343157   \n",
       "std                208.851818               87.331396              125.651302   \n",
       "min               -999.000000             -999.000000             -999.000000   \n",
       "25%                  7.656000               11.960750               10.458750   \n",
       "50%                 12.888500               19.360000               15.781500   \n",
       "75%                 20.664000               30.738000               23.237250   \n",
       "max                196.997000              469.227000              277.583000   \n",
       "\n",
       "       DEHH072_PM1_dataGroup1  DEHH079_PM1_dataGroup1  DEHH081_PM1_dataGroup1  \n",
       "count             8760.000000             8760.000000             8760.000000  \n",
       "mean               -28.703924               -0.194743              -10.264745  \n",
       "std                209.301279              139.332240              174.797689  \n",
       "min               -999.000000             -999.000000             -999.000000  \n",
       "25%                  6.427250               11.132500               10.722500  \n",
       "50%                 11.748500               15.707000               16.113500  \n",
       "75%                 20.787250               22.993000               23.949250  \n",
       "max                113.427000              170.415000              537.024000  \n",
       "\n",
       "[8 rows x 2267 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Memory usage: \", (dffAll.memory_usage(index=True).sum()/1048576.0), \" MB\")\n",
    "dffAll.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have **wide** dataframe, containing timeseries of all pollutant concentrations for all sensors. The pollutant type and the sensor ID are encoded in column names. The minimal value of pollutant concentrations *-999.0* is equivalent to *NA* and will be imputted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/arrays/datetimes.py:1172: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  \"will drop timezone information.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_period</th>\n",
       "      <th>DESH001_O3_dataGroup1</th>\n",
       "      <th>DESH008_O3_dataGroup1</th>\n",
       "      <th>DESH013_O3_dataGroup1</th>\n",
       "      <th>DESH014_O3_dataGroup1</th>\n",
       "      <th>DESH015_O3_dataGroup1</th>\n",
       "      <th>DESH016_O3_dataGroup1</th>\n",
       "      <th>DESH023_O3_dataGroup1</th>\n",
       "      <th>DESH033_O3_dataGroup1</th>\n",
       "      <th>DESH035_O3_dataGroup1</th>\n",
       "      <th>...</th>\n",
       "      <th>DEHH015_PM1_dataGroup1</th>\n",
       "      <th>DEHH016_PM1_dataGroup1</th>\n",
       "      <th>DEHH026_PM1_dataGroup1</th>\n",
       "      <th>DEHH033_PM1_dataGroup1</th>\n",
       "      <th>DEHH059_PM1_dataGroup1</th>\n",
       "      <th>DEHH068_PM1_dataGroup1</th>\n",
       "      <th>DEHH070_PM1_dataGroup1</th>\n",
       "      <th>DEHH072_PM1_dataGroup1</th>\n",
       "      <th>DEHH079_PM1_dataGroup1</th>\n",
       "      <th>DEHH081_PM1_dataGroup1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2017-12-31 21:00</td>\n",
       "      <td>63.301</td>\n",
       "      <td>60.667</td>\n",
       "      <td>67.917</td>\n",
       "      <td>59.453</td>\n",
       "      <td>64.209</td>\n",
       "      <td>63.144</td>\n",
       "      <td>62.950</td>\n",
       "      <td>17.042</td>\n",
       "      <td>58.144</td>\n",
       "      <td>...</td>\n",
       "      <td>18.904</td>\n",
       "      <td>5.162</td>\n",
       "      <td>33.793</td>\n",
       "      <td>16.538</td>\n",
       "      <td>29.383</td>\n",
       "      <td>63.372</td>\n",
       "      <td>27.154</td>\n",
       "      <td>8.836</td>\n",
       "      <td>12.413</td>\n",
       "      <td>8.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2017-12-31 22:00</td>\n",
       "      <td>70.473</td>\n",
       "      <td>62.127</td>\n",
       "      <td>65.207</td>\n",
       "      <td>60.882</td>\n",
       "      <td>68.517</td>\n",
       "      <td>67.690</td>\n",
       "      <td>61.775</td>\n",
       "      <td>17.042</td>\n",
       "      <td>63.060</td>\n",
       "      <td>...</td>\n",
       "      <td>22.250</td>\n",
       "      <td>10.204</td>\n",
       "      <td>47.489</td>\n",
       "      <td>26.634</td>\n",
       "      <td>32.953</td>\n",
       "      <td>74.021</td>\n",
       "      <td>24.785</td>\n",
       "      <td>8.177</td>\n",
       "      <td>15.343</td>\n",
       "      <td>6.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2017-12-31 23:00</td>\n",
       "      <td>69.297</td>\n",
       "      <td>71.514</td>\n",
       "      <td>68.926</td>\n",
       "      <td>69.438</td>\n",
       "      <td>76.856</td>\n",
       "      <td>70.269</td>\n",
       "      <td>68.019</td>\n",
       "      <td>17.042</td>\n",
       "      <td>74.892</td>\n",
       "      <td>...</td>\n",
       "      <td>16.465</td>\n",
       "      <td>11.866</td>\n",
       "      <td>54.099</td>\n",
       "      <td>25.612</td>\n",
       "      <td>24.207</td>\n",
       "      <td>70.609</td>\n",
       "      <td>25.648</td>\n",
       "      <td>6.642</td>\n",
       "      <td>15.602</td>\n",
       "      <td>5.610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     observation_period  DESH001_O3_dataGroup1  DESH008_O3_dataGroup1  \\\n",
       "8757   2017-12-31 21:00                 63.301                 60.667   \n",
       "8758   2017-12-31 22:00                 70.473                 62.127   \n",
       "8759   2017-12-31 23:00                 69.297                 71.514   \n",
       "\n",
       "      DESH013_O3_dataGroup1  DESH014_O3_dataGroup1  DESH015_O3_dataGroup1  \\\n",
       "8757                 67.917                 59.453                 64.209   \n",
       "8758                 65.207                 60.882                 68.517   \n",
       "8759                 68.926                 69.438                 76.856   \n",
       "\n",
       "      DESH016_O3_dataGroup1  DESH023_O3_dataGroup1  DESH033_O3_dataGroup1  \\\n",
       "8757                 63.144                 62.950                 17.042   \n",
       "8758                 67.690                 61.775                 17.042   \n",
       "8759                 70.269                 68.019                 17.042   \n",
       "\n",
       "      DESH035_O3_dataGroup1  ...  DEHH015_PM1_dataGroup1  \\\n",
       "8757                 58.144  ...                  18.904   \n",
       "8758                 63.060  ...                  22.250   \n",
       "8759                 74.892  ...                  16.465   \n",
       "\n",
       "      DEHH016_PM1_dataGroup1  DEHH026_PM1_dataGroup1  DEHH033_PM1_dataGroup1  \\\n",
       "8757                   5.162                  33.793                  16.538   \n",
       "8758                  10.204                  47.489                  26.634   \n",
       "8759                  11.866                  54.099                  25.612   \n",
       "\n",
       "      DEHH059_PM1_dataGroup1  DEHH068_PM1_dataGroup1  DEHH070_PM1_dataGroup1  \\\n",
       "8757                  29.383                  63.372                  27.154   \n",
       "8758                  32.953                  74.021                  24.785   \n",
       "8759                  24.207                  70.609                  25.648   \n",
       "\n",
       "      DEHH072_PM1_dataGroup1  DEHH079_PM1_dataGroup1  DEHH081_PM1_dataGroup1  \n",
       "8757                   8.836                  12.413                   8.112  \n",
       "8758                   8.177                  15.343                   6.805  \n",
       "8759                   6.642                  15.602                   5.610  \n",
       "\n",
       "[3 rows x 2268 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffAll[dffAll == -999.0] = np.NaN\n",
    "dffAll.interpolate(method='linear', inplace=True, axis=0)\n",
    "dffAll['observation_period']=pd.to_datetime(dffAll['observation_period'])\n",
    "dffAll['observation_period']=dffAll['observation_period'].dt.to_period('H')\n",
    "dffAll.describe()\n",
    "#dffAll['observation_period'][0].end_time\n",
    "dffAll.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save the resulting dataset for further use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffAll.dtypes\n",
    "#fastparquet.write('Capstone.ETL/Capstone.etl.wide.1.0.parquet', dffAll)\n",
    "dffAll.to_csv('Capstone.ETL/Capstone.etl.wideCSV.1.0.gzip', compression='gzip')\n",
    "#pd.Period(pd.to_datetime(\"2017-01-01T00:00:00+01:00\"), freq='H').end_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Locations\n",
    "In order to use the spatial data one should have coordinates of air pollution measurements sensors.\n",
    "For the current study the county index for every individual sensor is needed. First all measurement stations IDs and the town names of the sensors locations are read to **SensorLocation** dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SensorID</th>\n",
       "      <th>SensorTown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>DEUB005</td>\n",
       "      <td>Lüder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>DEUB028</td>\n",
       "      <td>Zingst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>DEUB029</td>\n",
       "      <td>Suhl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>DEUB030</td>\n",
       "      <td>Stechlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>DEUB044</td>\n",
       "      <td>Garmisch-Partenkirchen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SensorID              SensorTown\n",
       "803  DEUB005                   Lüder\n",
       "804  DEUB028                  Zingst\n",
       "805  DEUB029                    Suhl\n",
       "806  DEUB030                Stechlin\n",
       "807  DEUB044  Garmisch-Partenkirchen"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick all tags from the XML file\n",
    "Etree = etree.parse(\"Capstone.rawData/AQD_DE_D_2017/DE_D_allInOne_metaMeasurements_2017.xml\")\n",
    "Eroot = Etree.getroot()\n",
    "Eroot.tag\n",
    "Eroot.attrib\n",
    "AllTags = [elem.tag for elem in Eroot.iter()]\n",
    "\n",
    "# get correct tag names for 'municipality', 'EUStationCode' and 'featureMember':\n",
    "varMUN = [s for s in AllTags if 'municipality' in s][0]\n",
    "varID  = [s for s in AllTags if 'EUStationCode' in s][0]\n",
    "varFeatMem = [s for s in AllTags if 'featureMember' in s][0]\n",
    "\n",
    "IDs=[]\n",
    "MUNs=[]\n",
    "# read 'municipality' and 'EUStationCode' to SensorLocation dataframe:\n",
    "for varr in Eroot.iter(varFeatMem):\n",
    "    for child in varr.iter(varMUN):\n",
    "        MUNs.append(child.text)\n",
    "        for child2 in varr.iter(varID):\n",
    "            IDs.append(child2.text)\n",
    "SensorLocation=pd.DataFrame({'SensorID': IDs, 'SensorTown': MUNs})\n",
    "SensorLocation.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to map town names to county names, used in the health related datasets, the town-county table **dfCT** will be created. It contains 5-digit county-id (not unique, but characterizing counties in some vicinity), name of town and county: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countyid</th>\n",
       "      <th>town</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16116</th>\n",
       "      <td>16077</td>\n",
       "      <td>Starkenberg</td>\n",
       "      <td>Schmölln/Thür.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16117</th>\n",
       "      <td>16077</td>\n",
       "      <td>Thonhausen</td>\n",
       "      <td>Schmölln/Thür.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16118</th>\n",
       "      <td>16077</td>\n",
       "      <td>Treben</td>\n",
       "      <td>Schmölln/Thür.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16119</th>\n",
       "      <td>16077</td>\n",
       "      <td>Vollmershain</td>\n",
       "      <td>Schmölln/Thür.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16120</th>\n",
       "      <td>16077</td>\n",
       "      <td>Windischleuba</td>\n",
       "      <td>Schmölln/Thür.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       countyid           town          county\n",
       "16116     16077    Starkenberg  Schmölln/Thür.\n",
       "16117     16077     Thonhausen  Schmölln/Thür.\n",
       "16118     16077         Treben  Schmölln/Thür.\n",
       "16119     16077   Vollmershain  Schmölln/Thür.\n",
       "16120     16077  Windischleuba  Schmölln/Thür."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [(10, 15), (22, 71), (72, 121)]\n",
    "dfCT = pd.read_fwf(\"Capstone.rawData/GV100AD3107/GV100AD_310719.ASC\", \n",
    "                     colspecs=columns, names=['countyid','town','county'],\n",
    "                     encoding=\"iso8859_1\")\n",
    "dfCT=dfCT.fillna(method='ffill')\n",
    "\n",
    "dfCT['town'] = dfCT['town'].str.split(\",\").str[0]\n",
    "dfCT.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevalence of Heart failures\n",
    "The central dataframe of the model will contain list of counties, prevalence of disease(s) in this counties, and the set of air-pollution-based features. Let's load the *Prevalence of Heart failures* dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xls sheet names:  ['Hintergrundinformationen', 'Daten']\n",
      "             Region  Regions-ID  KV           Kreistyp  Wert  Bundeswert\n",
      "0            Lk.Hof        9475  BY  Ländliches Umland  6.43        3.11\n",
      "1  Mansfeld-Südharz       15087  ST    Ländlicher Raum  6.37        3.11\n",
      "2               Hof        9464  BY  Ländliches Umland  6.36        3.11\n",
      "Number of duplicates in Regions-ID column:  0\n"
     ]
    }
   ],
   "source": [
    "xlsx_file = pd.ExcelFile(\"Capstone.rawData/Heart_2017/data_id_97_kreis11_2_j_1483228800.xlsx\")\n",
    "print(\"xls sheet names: \",xlsx_file.sheet_names)\n",
    "dfHeart = xlsx_file.parse('Daten', header=3, decimal=\",\") \n",
    "print(dfHeart.head(3))\n",
    "print(\"Number of duplicates in Regions-ID column: \", dfHeart.duplicated(['Regions-ID']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping will start from setting the **countyID** to every **sensorID** in the **SensorLocation** dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SensorLocation = (SensorLocation.join(dfCT[['countyid','town']].set_index('town'),\n",
    "                                      on='SensorTown')).drop_duplicates(subset=['SensorID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the resulting table it was found, that 30 of 804 entries have not resolved **countyid**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sensors:  SensorID      808\n",
      "SensorTown    808\n",
      "countyid      778\n",
      "dtype: int64\n",
      "Number of sensors with unresolved countyid:  SensorID      30\n",
      "SensorTown    30\n",
      "countyid       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of sensors: \", SensorLocation.count())\n",
    "print(\"Number of sensors with unresolved countyid: \", SensorLocation[SensorLocation.isna().any(axis=1)].count())\n",
    "#print(\"List of unresolved sensors:\")\n",
    "#SensorLocation[SensorLocation.isna().any(axis=1)]\n",
    "#print(\"Number of duplicates in SensorID column: \", SensorLocation.duplicated(['SensorID']).sum())\n",
    "#SensorLocation.loc[SensorLocation.duplicated(['SensorID'])==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment it is easier to drop these 4% of sensor's data. Otherwise this table could be corrected manually, since it has reasonable size, and it's contents (sensor lables/county codes) hardly changes in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SensorID</th>\n",
       "      <th>SensorTown</th>\n",
       "      <th>countyid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBB007</td>\n",
       "      <td>Elsterwerda</td>\n",
       "      <td>12062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBB021</td>\n",
       "      <td>Potsdam</td>\n",
       "      <td>12054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEBB026</td>\n",
       "      <td>Spremberg</td>\n",
       "      <td>12071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBB029</td>\n",
       "      <td>Schwedt/Oder</td>\n",
       "      <td>12073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEBB032</td>\n",
       "      <td>Eisenhüttenstadt</td>\n",
       "      <td>12067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SensorID        SensorTown  countyid\n",
       "0  DEBB007       Elsterwerda     12062\n",
       "1  DEBB021           Potsdam     12054\n",
       "2  DEBB026         Spremberg     12071\n",
       "3  DEBB029      Schwedt/Oder     12073\n",
       "4  DEBB032  Eisenhüttenstadt     12067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SensorLocation=SensorLocation.dropna()\n",
    "SensorLocation=SensorLocation.astype({'countyid':int})\n",
    "SensorLocation.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally this dataframe will be saved for further use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SensorLocation.to_csv('Capstone.ETL/Capstone.etl.SensorLocationCSV.1.0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
