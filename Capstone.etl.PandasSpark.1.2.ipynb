{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "\n# Advanced Data Science Capstone\n\n## Correlation of air pollution and Prevalence of Asthma bronchiale in Germany  \n\n## ETL, Data cleansing", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "### The deliverables\nThe deliverables of the current stage:\n\n - current notebook as the process documentation\n - Spark data frame of the \"wide\" type, containing time series of pollutants concentrations for every available sensor\n - Spark data frame of the \"long\" type, containing time series of **selected** pollutants concentrations, **countyID** and a pollotant label\n - Spark data frame with disease prevalence column (Asthma bronchiale) and a county id\n \n### ETL\n #### Data Sources\n  -  The officially published data sets by **Gesch\u00e4fts- und Koordinierungsstelle GovData**, the search engine is available at https://www.govdata.de/web/guest/suchen.\n  - Data stream **E1a** contains measured (Link to Data stream **D**) values of gas phase pollutants (e.g. Ozone, NO2, SO2, CO), particle pollutants (e.g. dust) and dust constituants (e.g. heavy metals, PAK in PM10, PM2.5, TSP) as well es total deposition (BULK), wet deposition and meteorologic data (e.g. temperature, wind, pressure)for every measurement location.\n  - The data for years 2013 - 2018 is currently available. For the project I will limit myself with 2016 data (due to limited availability of the health related data sets), however the method and the model are easily extendable for the data for other years.\n  - Compressed dataset is available at https://datahub.uba.de/server/rest/directories/arcgisforinspire/INSPIRE/aqd_MapServer/Daten/AQD_DE_E1a_2016.zip .\n #### Data cleansing\n  - The air quality data sets are claimed to be \"validated\", so most work for cleansing the data is already done.\n  - The incomplete files from the datasets (not having \"hour\" in the name) are ignored.\n  - Few missing values appearing in the time series as negative values of the pollutant concentrations will be imputed.\n \n #### Enterprise data storage\n  - Saving Spark data frames in Parquet format", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import urllib.request\nimport xml.etree.ElementTree as ET\nfrom lxml import etree\nimport pandas as pd\nimport numpy as np\n\nimport re, collections\nfrom io import StringIO\nimport os, fnmatch\n#, fastparquet\n\nimport matplotlib.pyplot as plt\n\ndef SelectAllXMLsensorID():\n    varFull = [s for s in AllTags if 'value' in s][0]\n    return([re.sub(r'[^a-zA-Z0-9:]*\\'{http(.*)$', r'', re.sub(r'^.*AQD\\/SPO.DE_', r'', str(varr.attrib))) for varr in Eroot.iter(varFull) if 'AQD' in str(varr.attrib)]) \n\n"
        }, 
        {
            "source": "Now the files with pollutant concentration time series for the given year will be loaded to the **dffAll** Pandas data frame of the **wide** format. During the load procedure **consistensy** of **files** and **column** names will be checked.\n\nFirst, all the necessary files are downloaded:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Archive:  Capstone.rawData/AQD_DE_E1a_2016/AQD_DE_E1a_2016.zip\n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_NOx_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_PM1_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_PM2_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_PM2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SH_2016_SO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_CO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_PM1_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_PM2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SL_2016_SO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_CHB_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_CHT_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_NOx_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_PM1_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_PM2_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_SN_2016_SO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_CHB_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_CHT_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_CO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_H2S_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_NOx_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_PM1_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_PM2_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_PM2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_ST_2016_SO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_CHB_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_CHT_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_CO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_NOx_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_PM2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_TH_2016_SO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_CO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_HG_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_NO2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_NOx_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_NO_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_O3_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_PM0_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_PM1_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_PM1_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_PM2_day.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_PM2_hour.xml  \n  inflating: Capstone.rawData/AQD_DE_E1a_2016/DE_UB_2016_SO2_hour.xml  \nArchive:  Capstone.rawData/AQD_DE_D_2016.zip\n  inflating: Capstone.rawData/DE_D_allInOne_metaMeasurements_2016.xml  \n  inflating: Capstone.rawData/DE_D_Model_2016.xml  \nArchive:  Capstone.rawData/GV100AD3107.zip\n  inflating: Capstone.rawData/GV100AD3107/Datensatzbeschreibung_GV100AD.pdf  \n  inflating: Capstone.rawData/GV100AD3107/GV100AD_310719.ASC  \n  inflating: Capstone.rawData/GV100AD3107/Hinweise.txt  \n"
                }
            ], 
            "source": "!rm -rf ./Capstone.rawData\n## Download and decompress the dataset itself:\n!mkdir Capstone.rawData\n#!ls -l Capstone.rawData/\n\n##### Pollution 2016\n!mkdir Capstone.rawData/AQD_DE_E1a_2016\nurllib.request.urlretrieve(\"https://datahub.uba.de/server/rest/directories/arcgisforinspire/INSPIRE/aqd_MapServer/Daten/AQD_DE_E1a_2016.zip\", \"Capstone.rawData/AQD_DE_E1a_2016.zip\")\n!mv Capstone.rawData/AQD_DE_E1a_2016.zip Capstone.rawData/AQD_DE_E1a_2016/\n!unzip Capstone.rawData/AQD_DE_E1a_2016/AQD_DE_E1a_2016.zip -d Capstone.rawData/\n!rm Capstone.rawData/AQD_DE_E1a_2016/AQD_DE_E1a_2016.zip\n\n##### Sensor locations 2016\nurllib.request.urlretrieve(\"https://datahub.uba.de/server/rest/directories/arcgisforinspire/INSPIRE/aqd_MapServer/Daten/AQD_DE_D_2016.zip\", \"Capstone.rawData/AQD_DE_D_2016.zip\")\n!unzip Capstone.rawData/AQD_DE_D_2016.zip -d Capstone.rawData/\n!rm Capstone.rawData/AQD_DE_D_2016.zip\n\n##### Prevalence of Asthma bronchiale 2016 \n!mkdir Capstone.rawData/Asthma_2016\nurllib.request.urlretrieve(\"https://www.versorgungsatlas.de/fileadmin/excel/data_id_92_kreis11_1_j_1451606400.xlsx\", \"Capstone.rawData/Asthma_2016/data_id_92_kreis11_1_j_1451606400.xlsx\")\n\n##### Town-county dataset:\nurllib.request.urlretrieve(\"https://www.destatis.de/DE/Themen/Laender-Regionen/Regionales/Gemeindeverzeichnis/Administrativ/Archiv/GV100ADQ/GV100AD3107.zip?__blob=publicationFile\",\n                           \"Capstone.rawData/GV100AD3107.zip\")\n!mkdir Capstone.rawData/GV100AD3107\n!unzip Capstone.rawData/GV100AD3107.zip -d Capstone.rawData/GV100AD3107/\n!rm Capstone.rawData/GV100AD3107.zip"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of files in the dataset 51\n"
                }
            ], 
            "source": "AirE1aDir='Capstone.rawData/AQD_DE_E1a_2016/'\n\n#!ls Capstone.rawData/AQD_DE_E1a_2016/*hour*\nFilesHour=[]\n\nfor file in os.listdir(AirE1aDir):\n    if fnmatch.fnmatch(file, '*hour*'):\n        FilesHour.append(file)\nprint(\"Number of files in the dataset\", len(FilesHour))\n\n# shortening the process for debugging purposes\n#FilesHour=FilesHour[0:3]        \n\ndffAll=pd.DataFrame(index=range(0,8760))  # 8760 hours in the year\n\n# add First column with Observation Times:\ndff=[]  # Temporary list for DataFrames\n\nfile=FilesHour[0]\nEtree = ET.parse(AirE1aDir+file)\nEroot = Etree.getroot()\nEroot.tag\nEroot.attrib\nAllTags = [elem.tag for elem in Eroot.iter()]\nvarFull = [s for s in AllTags if 'values' in s][0]\nfor varr in Eroot.iter(varFull):\n    dff.append(pd.read_csv(StringIO((varr.text).replace(\"@@\",\"\\n\")), sep=\",\", header=None))\ndffAll=pd.concat([dffAll, dff[0][[0]]], axis=1)\ndffAll.columns=['observation_period']\n\n\n# get all tags in xml file; Note, that the actual data is kept as a TEXT of *values* tags \nfor file in FilesHour:\n    Etree = ET.parse(AirE1aDir+file)\n    Eroot = Etree.getroot()\n    Eroot.tag\n    Eroot.attrib\n    AllTags = [elem.tag for elem in Eroot.iter()]\n    \n    ColNamesExp=SelectAllXMLsensorID()\n# Compare column names with file names, they should encode same country, state and pollutant\n    for ColName in ColNamesExp:\n        if ((ColName[0:2]!=file[0:2]) or (ColName[2:4]!=file[3:5]) or (ColName[8:11]!=file[11:14])):\n            print(\"Inconsistency in file and column names: \", file, ColName)\n            exit()\n    \n    varFull = [s for s in AllTags if 'values' in s][0]\n    \n    dff=[] # Temporary list for DataFrames\n# reading actual pollutant data fiom the text field:    \n    for varr in Eroot.iter(varFull):\n        dff.append(pd.read_csv(StringIO((varr.text).replace(\"@@\",\"\\n\")), sep=\",\", header=None))\n\n# checking, that measurment timestamps are identical in the files read       \n    for s in range(0,len(dff)):\n        if not (dffAll['observation_period']).equals(dff[s][0]):\n            print(\"Inconsistency of observation times in the following files: \", file, FilesHour[0])\n            exit()\n\n        \n# select column 4 - pollutant concentration:\n    dff=pd.concat([dff[s][4] for s in range(0,len(dff))], axis=1)\n    dff.columns=ColNamesExp\n   \n    dffAll=pd.concat([dffAll, dff], axis=1)"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Memory usage:  35.25080871582031  MB\n"
                }, 
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DESL002_O3_dataGroup1</th>\n      <th>DESL003_O3_dataGroup1</th>\n      <th>DESL011_O3_dataGroup1</th>\n      <th>DESL012_O3_dataGroup1</th>\n      <th>DESL017_O3_dataGroup1</th>\n      <th>DESL018_O3_dataGroup1</th>\n      <th>DESL019_O3_dataGroup1</th>\n      <th>DESL020_O3_dataGroup1</th>\n      <th>DEST002_NOx_dataGroup1</th>\n      <th>DEST011_NOx_dataGroup1</th>\n      <th>...</th>\n      <th>DETH041_NOx_dataGroup1</th>\n      <th>DETH042_NOx_dataGroup1</th>\n      <th>DETH043_NOx_dataGroup1</th>\n      <th>DETH060_NOx_dataGroup1</th>\n      <th>DETH061_NOx_dataGroup1</th>\n      <th>DETH072_NOx_dataGroup1</th>\n      <th>DETH083_NOx_dataGroup1</th>\n      <th>DETH091_NOx_dataGroup1</th>\n      <th>DETH093_NOx_dataGroup1</th>\n      <th>DETH095_NOx_dataGroup1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>...</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n      <td>8784.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>43.896763</td>\n      <td>40.238199</td>\n      <td>46.100140</td>\n      <td>35.718489</td>\n      <td>40.191250</td>\n      <td>37.712905</td>\n      <td>52.681432</td>\n      <td>23.858329</td>\n      <td>10.888974</td>\n      <td>14.562116</td>\n      <td>...</td>\n      <td>22.183709</td>\n      <td>1.380379</td>\n      <td>91.651819</td>\n      <td>27.095028</td>\n      <td>-12.454350</td>\n      <td>75.664406</td>\n      <td>47.300504</td>\n      <td>60.138941</td>\n      <td>12.090326</td>\n      <td>24.111151</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>30.773361</td>\n      <td>50.174665</td>\n      <td>58.471116</td>\n      <td>39.468144</td>\n      <td>29.991761</td>\n      <td>29.648842</td>\n      <td>66.185304</td>\n      <td>98.132662</td>\n      <td>85.650998</td>\n      <td>78.668791</td>\n      <td>...</td>\n      <td>64.029171</td>\n      <td>73.688854</td>\n      <td>107.314920</td>\n      <td>74.223164</td>\n      <td>135.407990</td>\n      <td>100.568808</td>\n      <td>78.420450</td>\n      <td>151.474130</td>\n      <td>142.454843</td>\n      <td>69.056018</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.190000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>0.850000</td>\n      <td>0.450000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>...</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>18.437500</td>\n      <td>18.085000</td>\n      <td>27.077500</td>\n      <td>9.430000</td>\n      <td>12.710000</td>\n      <td>10.800000</td>\n      <td>36.980000</td>\n      <td>9.090000</td>\n      <td>5.831979</td>\n      <td>8.993116</td>\n      <td>...</td>\n      <td>7.920671</td>\n      <td>1.912500</td>\n      <td>33.973596</td>\n      <td>6.824235</td>\n      <td>1.912500</td>\n      <td>19.969051</td>\n      <td>20.649628</td>\n      <td>20.951626</td>\n      <td>8.268646</td>\n      <td>8.278996</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>42.235000</td>\n      <td>40.845000</td>\n      <td>47.780000</td>\n      <td>31.965000</td>\n      <td>37.055000</td>\n      <td>33.995000</td>\n      <td>55.915000</td>\n      <td>28.800000</td>\n      <td>10.978419</td>\n      <td>13.728892</td>\n      <td>...</td>\n      <td>14.229478</td>\n      <td>4.943564</td>\n      <td>66.052300</td>\n      <td>12.092738</td>\n      <td>4.314944</td>\n      <td>48.292873</td>\n      <td>37.752516</td>\n      <td>48.175444</td>\n      <td>14.643343</td>\n      <td>14.772819</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>63.242500</td>\n      <td>60.722500</td>\n      <td>66.102500</td>\n      <td>57.080000</td>\n      <td>61.195000</td>\n      <td>57.795000</td>\n      <td>72.840000</td>\n      <td>51.100000</td>\n      <td>20.749995</td>\n      <td>23.072270</td>\n      <td>...</td>\n      <td>29.716350</td>\n      <td>8.187625</td>\n      <td>123.019032</td>\n      <td>28.326970</td>\n      <td>7.221885</td>\n      <td>104.310432</td>\n      <td>64.733919</td>\n      <td>99.112829</td>\n      <td>30.998374</td>\n      <td>31.944511</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>181.830000</td>\n      <td>164.150000</td>\n      <td>169.770000</td>\n      <td>161.420000</td>\n      <td>174.420000</td>\n      <td>175.710000</td>\n      <td>170.860000</td>\n      <td>131.620000</td>\n      <td>232.751900</td>\n      <td>256.317600</td>\n      <td>...</td>\n      <td>304.121277</td>\n      <td>58.210953</td>\n      <td>850.619751</td>\n      <td>616.160645</td>\n      <td>79.711472</td>\n      <td>711.213379</td>\n      <td>453.616028</td>\n      <td>746.290649</td>\n      <td>520.957947</td>\n      <td>565.633850</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows \u00d7 525 columns</p>\n</div>", 
                        "text/plain": "       DESL002_O3_dataGroup1  DESL003_O3_dataGroup1  DESL011_O3_dataGroup1  \\\ncount            8784.000000            8784.000000            8784.000000   \nmean               43.896763              40.238199              46.100140   \nstd                30.773361              50.174665              58.471116   \nmin                 0.190000            -999.000000            -999.000000   \n25%                18.437500              18.085000              27.077500   \n50%                42.235000              40.845000              47.780000   \n75%                63.242500              60.722500              66.102500   \nmax               181.830000             164.150000             169.770000   \n\n       DESL012_O3_dataGroup1  DESL017_O3_dataGroup1  DESL018_O3_dataGroup1  \\\ncount            8784.000000            8784.000000            8784.000000   \nmean               35.718489              40.191250              37.712905   \nstd                39.468144              29.991761              29.648842   \nmin              -999.000000               0.850000               0.450000   \n25%                 9.430000              12.710000              10.800000   \n50%                31.965000              37.055000              33.995000   \n75%                57.080000              61.195000              57.795000   \nmax               161.420000             174.420000             175.710000   \n\n       DESL019_O3_dataGroup1  DESL020_O3_dataGroup1  DEST002_NOx_dataGroup1  \\\ncount            8784.000000            8784.000000             8784.000000   \nmean               52.681432              23.858329               10.888974   \nstd                66.185304              98.132662               85.650998   \nmin              -999.000000            -999.000000             -999.000000   \n25%                36.980000               9.090000                5.831979   \n50%                55.915000              28.800000               10.978419   \n75%                72.840000              51.100000               20.749995   \nmax               170.860000             131.620000              232.751900   \n\n       DEST011_NOx_dataGroup1  ...  DETH041_NOx_dataGroup1  \\\ncount             8784.000000  ...             8784.000000   \nmean                14.562116  ...               22.183709   \nstd                 78.668791  ...               64.029171   \nmin               -999.000000  ...             -999.000000   \n25%                  8.993116  ...                7.920671   \n50%                 13.728892  ...               14.229478   \n75%                 23.072270  ...               29.716350   \nmax                256.317600  ...              304.121277   \n\n       DETH042_NOx_dataGroup1  DETH043_NOx_dataGroup1  DETH060_NOx_dataGroup1  \\\ncount             8784.000000             8784.000000             8784.000000   \nmean                 1.380379               91.651819               27.095028   \nstd                 73.688854              107.314920               74.223164   \nmin               -999.000000             -999.000000             -999.000000   \n25%                  1.912500               33.973596                6.824235   \n50%                  4.943564               66.052300               12.092738   \n75%                  8.187625              123.019032               28.326970   \nmax                 58.210953              850.619751              616.160645   \n\n       DETH061_NOx_dataGroup1  DETH072_NOx_dataGroup1  DETH083_NOx_dataGroup1  \\\ncount             8784.000000             8784.000000             8784.000000   \nmean               -12.454350               75.664406               47.300504   \nstd                135.407990              100.568808               78.420450   \nmin               -999.000000             -999.000000             -999.000000   \n25%                  1.912500               19.969051               20.649628   \n50%                  4.314944               48.292873               37.752516   \n75%                  7.221885              104.310432               64.733919   \nmax                 79.711472              711.213379              453.616028   \n\n       DETH091_NOx_dataGroup1  DETH093_NOx_dataGroup1  DETH095_NOx_dataGroup1  \ncount             8784.000000             8784.000000             8784.000000  \nmean                60.138941               12.090326               24.111151  \nstd                151.474130              142.454843               69.056018  \nmin               -999.000000             -999.000000             -999.000000  \n25%                 20.951626                8.268646                8.278996  \n50%                 48.175444               14.643343               14.772819  \n75%                 99.112829               30.998374               31.944511  \nmax                746.290649              520.957947              565.633850  \n\n[8 rows x 525 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "print(\"Memory usage: \", (dffAll.memory_usage(index=True).sum()/1048576.0), \" MB\")\ndffAll.describe()"
        }, 
        {
            "source": "Now we have **wide** data frame, containing timeseries of all pollutant concentrations for all sensors. The pollutant type and the sensor ID are encoded in column names. The minimal value of pollutant concentrations *-999.0* is equivalent to *NA* and will be imputted, as well as all negative values (the concentration can not be negative). The limit for imputation will be set to 876, i.e. *NA* sequences exceeding 10% of the year will not be imputted. Since the number of heavily corrupted columns is below 3%, they will be dropped in favor to the information quality:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n  app.launch_new_instance()\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The number of corrupted columns is  10  of  526\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py:1172: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n  \"will drop timezone information.\", UserWarning)\n"
                }, 
                {
                    "execution_count": 4, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>observation_period</th>\n      <th>DESL002_O3_dataGroup1</th>\n      <th>DESL003_O3_dataGroup1</th>\n      <th>DESL011_O3_dataGroup1</th>\n      <th>DESL012_O3_dataGroup1</th>\n      <th>DESL017_O3_dataGroup1</th>\n      <th>DESL018_O3_dataGroup1</th>\n      <th>DESL019_O3_dataGroup1</th>\n      <th>DESL020_O3_dataGroup1</th>\n      <th>DEST002_NOx_dataGroup1</th>\n      <th>...</th>\n      <th>DETH041_NOx_dataGroup1</th>\n      <th>DETH042_NOx_dataGroup1</th>\n      <th>DETH043_NOx_dataGroup1</th>\n      <th>DETH060_NOx_dataGroup1</th>\n      <th>DETH061_NOx_dataGroup1</th>\n      <th>DETH072_NOx_dataGroup1</th>\n      <th>DETH083_NOx_dataGroup1</th>\n      <th>DETH091_NOx_dataGroup1</th>\n      <th>DETH093_NOx_dataGroup1</th>\n      <th>DETH095_NOx_dataGroup1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8781</th>\n      <td>2016-12-31 21:00</td>\n      <td>1.64</td>\n      <td>5.08</td>\n      <td>2.90</td>\n      <td>4.00</td>\n      <td>4.19</td>\n      <td>2.42</td>\n      <td>25.44</td>\n      <td>2.72</td>\n      <td>15.716239</td>\n      <td>...</td>\n      <td>77.027954</td>\n      <td>30.488693</td>\n      <td>90.341911</td>\n      <td>60.260674</td>\n      <td>16.560911</td>\n      <td>57.726231</td>\n      <td>132.491394</td>\n      <td>96.647903</td>\n      <td>142.340775</td>\n      <td>113.357315</td>\n    </tr>\n    <tr>\n      <th>8782</th>\n      <td>2016-12-31 22:00</td>\n      <td>2.02</td>\n      <td>10.67</td>\n      <td>3.10</td>\n      <td>3.91</td>\n      <td>4.29</td>\n      <td>2.35</td>\n      <td>28.11</td>\n      <td>2.41</td>\n      <td>14.546514</td>\n      <td>...</td>\n      <td>80.224121</td>\n      <td>31.683720</td>\n      <td>72.076004</td>\n      <td>61.261394</td>\n      <td>17.742168</td>\n      <td>67.070229</td>\n      <td>111.189499</td>\n      <td>100.438667</td>\n      <td>99.762787</td>\n      <td>88.717621</td>\n    </tr>\n    <tr>\n      <th>8783</th>\n      <td>2016-12-31 23:00</td>\n      <td>3.32</td>\n      <td>5.73</td>\n      <td>4.13</td>\n      <td>4.25</td>\n      <td>4.25</td>\n      <td>2.88</td>\n      <td>23.48</td>\n      <td>6.45</td>\n      <td>9.365071</td>\n      <td>...</td>\n      <td>71.562309</td>\n      <td>33.108055</td>\n      <td>79.259933</td>\n      <td>76.318123</td>\n      <td>18.049219</td>\n      <td>74.662857</td>\n      <td>101.533669</td>\n      <td>58.314323</td>\n      <td>52.971664</td>\n      <td>59.788193</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows \u00d7 516 columns</p>\n</div>", 
                        "text/plain": "     observation_period  DESL002_O3_dataGroup1  DESL003_O3_dataGroup1  \\\n8781   2016-12-31 21:00                   1.64                   5.08   \n8782   2016-12-31 22:00                   2.02                  10.67   \n8783   2016-12-31 23:00                   3.32                   5.73   \n\n      DESL011_O3_dataGroup1  DESL012_O3_dataGroup1  DESL017_O3_dataGroup1  \\\n8781                   2.90                   4.00                   4.19   \n8782                   3.10                   3.91                   4.29   \n8783                   4.13                   4.25                   4.25   \n\n      DESL018_O3_dataGroup1  DESL019_O3_dataGroup1  DESL020_O3_dataGroup1  \\\n8781                   2.42                  25.44                   2.72   \n8782                   2.35                  28.11                   2.41   \n8783                   2.88                  23.48                   6.45   \n\n      DEST002_NOx_dataGroup1  ...  DETH041_NOx_dataGroup1  \\\n8781               15.716239  ...               77.027954   \n8782               14.546514  ...               80.224121   \n8783                9.365071  ...               71.562309   \n\n      DETH042_NOx_dataGroup1  DETH043_NOx_dataGroup1  DETH060_NOx_dataGroup1  \\\n8781               30.488693               90.341911               60.260674   \n8782               31.683720               72.076004               61.261394   \n8783               33.108055               79.259933               76.318123   \n\n      DETH061_NOx_dataGroup1  DETH072_NOx_dataGroup1  DETH083_NOx_dataGroup1  \\\n8781               16.560911               57.726231              132.491394   \n8782               17.742168               67.070229              111.189499   \n8783               18.049219               74.662857              101.533669   \n\n      DETH091_NOx_dataGroup1  DETH093_NOx_dataGroup1  DETH095_NOx_dataGroup1  \n8781               96.647903              142.340775              113.357315  \n8782              100.438667               99.762787               88.717621  \n8783               58.314323               52.971664               59.788193  \n\n[3 rows x 516 columns]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "dffAll[dffAll.loc[:, dffAll.columns != 'observation_period'] < 0.0] = np.NaN\ndffAll.interpolate(method='linear', inplace=True, axis=0, limit=876, limit_direction='both')\nprint('The number of corrupted columns is ', len(dffAll.isna().sum().nonzero()[0]), ' of ', len(dffAll.columns))\ndffAll = dffAll.dropna(axis=1)\ndffAll['observation_period']=pd.to_datetime(dffAll['observation_period'])\ndffAll['observation_period']=dffAll['observation_period'].dt.to_period('H')\n#dffAll['observation_period'][0].end_time\ndffAll.tail(3)"
        }, 
        {
            "source": "### Saving Air Pollution DataFrame to COS\nNow we can save the resulting dataset for further use:\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "source": "### Sensor Locations\nIn order to use the spatial data one should have coordinates of air pollution measurements sensors.\nFor the current study the county index for every individual sensor is needed. First all measurement stations IDs and the town names of the sensors locations are read to **SensorLocation** dataframe:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 5, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SensorID</th>\n      <th>SensorTown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>762</th>\n      <td>DEUB005</td>\n      <td>L\u00fcder</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>DEUB028</td>\n      <td>Zingst</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>DEUB029</td>\n      <td>Suhl</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>DEUB030</td>\n      <td>Stechlin</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>DEUB044</td>\n      <td>Garmisch-Partenkirchen</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "    SensorID              SensorTown\n762  DEUB005                   L\u00fcder\n763  DEUB028                  Zingst\n764  DEUB029                    Suhl\n765  DEUB030                Stechlin\n766  DEUB044  Garmisch-Partenkirchen"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# pick all tags from the XML file\nEtree = etree.parse(\"Capstone.rawData/DE_D_allInOne_metaMeasurements_2016.xml\")\nEroot = Etree.getroot()\nEroot.tag\nEroot.attrib\nAllTags = [elem.tag for elem in Eroot.iter()]\n\n# get correct tag names for 'municipality', 'EUStationCode' and 'featureMember':\nvarMUN = [s for s in AllTags if 'municipality' in s][0]\nvarID  = [s for s in AllTags if 'EUStationCode' in s][0]\nvarFeatMem = [s for s in AllTags if 'featureMember' in s][0]\n\nIDs=[]\nMUNs=[]\n# read 'municipality' and 'EUStationCode' to SensorLocation dataframe:\nfor varr in Eroot.iter(varFeatMem):\n    for child in varr.iter(varMUN):\n        MUNs.append(child.text)\n        for child2 in varr.iter(varID):\n            IDs.append(child2.text)\nSensorLocation=pd.DataFrame({'SensorID': IDs, 'SensorTown': MUNs})\nSensorLocation.tail(5)"
        }, 
        {
            "source": "In order to map town names to county names, used in the health related datasets, the town-county table **dfCT** will be created. It contains 5-digit county-id (not unique, but characterizing counties in some vicinity), name of town and county: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CountyID</th>\n      <th>town</th>\n      <th>county</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16116</th>\n      <td>16077</td>\n      <td>Starkenberg</td>\n      <td>Schm\u00f6lln/Th\u00fcr.</td>\n    </tr>\n    <tr>\n      <th>16117</th>\n      <td>16077</td>\n      <td>Thonhausen</td>\n      <td>Schm\u00f6lln/Th\u00fcr.</td>\n    </tr>\n    <tr>\n      <th>16118</th>\n      <td>16077</td>\n      <td>Treben</td>\n      <td>Schm\u00f6lln/Th\u00fcr.</td>\n    </tr>\n    <tr>\n      <th>16119</th>\n      <td>16077</td>\n      <td>Vollmershain</td>\n      <td>Schm\u00f6lln/Th\u00fcr.</td>\n    </tr>\n    <tr>\n      <th>16120</th>\n      <td>16077</td>\n      <td>Windischleuba</td>\n      <td>Schm\u00f6lln/Th\u00fcr.</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "       CountyID           town          county\n16116     16077    Starkenberg  Schm\u00f6lln/Th\u00fcr.\n16117     16077     Thonhausen  Schm\u00f6lln/Th\u00fcr.\n16118     16077         Treben  Schm\u00f6lln/Th\u00fcr.\n16119     16077   Vollmershain  Schm\u00f6lln/Th\u00fcr.\n16120     16077  Windischleuba  Schm\u00f6lln/Th\u00fcr."
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "columns = [(10, 15), (22, 71), (72, 121)]\ndfCT = pd.read_fwf(\"Capstone.rawData/GV100AD3107/GV100AD_310719.ASC\", \n                     colspecs=columns, names=['CountyID','town','county'],\n                     encoding=\"iso8859_1\")\ndfCT=dfCT.fillna(method='ffill')\n\ndfCT['town'] = dfCT['town'].str.split(\",\").str[0]\ndfCT.tail(5)"
        }, 
        {
            "source": "### Prevalence of Asthma bronchiale\nThe central data frame of the model will contain list of counties, prevalence of disease(s) in this counties, and the set of air-pollution-based features. Let's load the *Prevalence of Asthma bronchiale* dataset: ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "xls sheet names:  ['Hintergrundinformationen', 'Daten']\n      Region  Regions-ID  KV             Kreistyp  Wert  Bundeswert\n0   Eisenach       16056  TH    L\u00e4ndliches Umland   8.9         5.7\n1  Sonneberg       16072  TH      L\u00e4ndlicher Raum   8.7         5.7\n2  Ammerland        3451  NI  Verdichtetes Umland   8.5         5.7\nNumber of duplicates in Regions-ID column:  0\n"
                }
            ], 
            "source": "xlsx_file = pd.ExcelFile(\"Capstone.rawData/Asthma_2016/data_id_92_kreis11_1_j_1451606400.xlsx\")\nprint(\"xls sheet names: \",xlsx_file.sheet_names)\ndfAsthma = xlsx_file.parse('Daten', header=3, decimal=\",\") \nprint(dfAsthma.head(3))\nprint(\"Number of duplicates in Regions-ID column: \", dfAsthma.duplicated(['Regions-ID']).sum())"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 8, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CountyID</th>\n      <th>DiseaseR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16056</td>\n      <td>8.9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16072</td>\n      <td>8.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3451</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16073</td>\n      <td>8.3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3151</td>\n      <td>8.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   CountyID  DiseaseR\n0     16056       8.9\n1     16072       8.7\n2      3451       8.5\n3     16073       8.3\n4      3151       8.2"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "dfAsthma = dfAsthma.drop(['Region', 'KV', 'Kreistyp', 'Bundeswert'], axis=1)\ndfAsthma.columns=['CountyID','DiseaseR']\ndfAsthma.head(5)"
        }, 
        {
            "source": "The mapping will start from setting the **CountyID** to every **sensorID** in the **SensorLocation** dataframe:\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "SensorLocation = (SensorLocation.join(dfCT[['CountyID','town']].set_index('town'),\n                                      on='SensorTown')).drop_duplicates(subset=['SensorID'])"
        }, 
        {
            "source": "Checking the resulting table it was found, that 23 of 767 entries have not resolved **CountyID**:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Total number of sensors:  SensorID      767\nSensorTown    767\nCountyID      744\ndtype: int64\nNumber of sensors with unresolved CountyID:  SensorID      23\nSensorTown    23\nCountyID       0\ndtype: int64\n"
                }
            ], 
            "source": "print(\"Total number of sensors: \", SensorLocation.count())\nprint(\"Number of sensors with unresolved CountyID: \", SensorLocation[SensorLocation.isna().any(axis=1)].count())\n#print(\"List of unresolved sensors:\")\n#SensorLocation[SensorLocation.isna().any(axis=1)]\n#print(\"Number of duplicates in SensorID column: \", SensorLocation.duplicated(['SensorID']).sum())\n#SensorLocation.loc[SensorLocation.duplicated(['SensorID'])==True]"
        }, 
        {
            "source": "At the moment it is easier to drop these 3% of sensor's data. Otherwise this table could be corrected manually, since it has reasonable size, and it's contents (sensor lables/county codes) hardly changes in time. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 11, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SensorID</th>\n      <th>SensorTown</th>\n      <th>CountyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DEBB007</td>\n      <td>Elsterwerda</td>\n      <td>12062</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DEBB021</td>\n      <td>Potsdam</td>\n      <td>12054</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>DEBB026</td>\n      <td>Spremberg</td>\n      <td>12071</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DEBB029</td>\n      <td>Schwedt/Oder</td>\n      <td>12073</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DEBB032</td>\n      <td>Eisenh\u00fcttenstadt</td>\n      <td>12067</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  SensorID        SensorTown  CountyID\n0  DEBB007       Elsterwerda     12062\n1  DEBB021           Potsdam     12054\n2  DEBB026         Spremberg     12071\n3  DEBB029      Schwedt/Oder     12073\n4  DEBB032  Eisenh\u00fcttenstadt     12067"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "SensorLocation=SensorLocation.dropna()\nSensorLocation=SensorLocation.astype({'CountyID':int})\nSensorLocation.head(5)"
        }, 
        {
            "source": "### Saving Sensor Locations and Asthma bronchiale Prevalence DataFrames to COS\nNow we can save the resulting dataset for further use:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "NameError", 
                    "evalue": "name 'spark' is not defined", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-12-e504da4bd45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSensorLocationSpark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSensorLocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mSensorLocationSpark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SensorLocation.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capstone-donotdelete-pr-zpykcz8f0kxuad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mAsthmaSpark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfAsthma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mAsthmaSpark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Asthma.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'capstone-donotdelete-pr-zpykcz8f0kxuad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "SensorLocationSpark = spark.createDataFrame(SensorLocation)\nSensorLocationSpark.write.parquet(cos.url('SensorLocation.parquet', 'capstone-donotdelete-pr-zpykcz8f0kxuad'))\n\nAsthmaSpark = spark.createDataFrame(dfAsthma)\nAsthmaSpark.write.parquet(cos.url('Asthma.parquet', 'capstone-donotdelete-pr-zpykcz8f0kxuad'))"
        }, 
        {
            "source": "### Constructing \"Long\" DataFrame", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 12, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>observation_period</th>\n      <th>SensorPollID</th>\n      <th>PollutantConc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-01 00:00</td>\n      <td>DESL002_O3_dataGroup1</td>\n      <td>7.01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-01 01:00</td>\n      <td>DESL002_O3_dataGroup1</td>\n      <td>6.53</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-01 02:00</td>\n      <td>DESL002_O3_dataGroup1</td>\n      <td>6.94</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-01 03:00</td>\n      <td>DESL002_O3_dataGroup1</td>\n      <td>19.91</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-01 04:00</td>\n      <td>DESL002_O3_dataGroup1</td>\n      <td>30.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  observation_period           SensorPollID  PollutantConc\n0   2016-01-01 00:00  DESL002_O3_dataGroup1           7.01\n1   2016-01-01 01:00  DESL002_O3_dataGroup1           6.53\n2   2016-01-01 02:00  DESL002_O3_dataGroup1           6.94\n3   2016-01-01 03:00  DESL002_O3_dataGroup1          19.91\n4   2016-01-01 04:00  DESL002_O3_dataGroup1          30.75"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "dffAllLong = pd.melt(dffAll, id_vars=['observation_period'], var_name='SensorPollID', value_name='PollutantConc')\ndffAllLong.head()"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import gc\ndel dffAll\ndel dff\n\ngc.collect()\n\nSensorCountyDict = dict(zip(SensorLocation.SensorID, SensorLocation.CountyID))"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#dffAllLong['CountyID'] = dffAllLong.apply(lambda row: re.search('(^.{7})', row['SensorPollID']).group(1), axis=1)\nColumnCountyID = pd.DataFrame()\nColumnSensorID = pd.DataFrame()\nColumnSensorID['SensorID'] = dffAllLong.apply(lambda row: re.search('(^.{7})', row['SensorPollID']).group(1), axis=1)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Memory usage:  34.51362609863281  MB\n"
                }
            ], 
            "source": "print(\"Memory usage: \", (ColumnSensorID.memory_usage(index=True).sum()/1048576.0), \" MB\")"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#ColumnCountyID.replace({'CountyID': SensorCountyDict})\nColumnCountyID['CountyID'] = ColumnSensorID['SensorID'].map(SensorCountyDict)\n#.dropna().astype('int64')"
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CountyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10045.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10045.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10045.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10045.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10045.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "   CountyID\n0   10045.0\n1   10045.0\n2   10045.0\n3   10045.0\n4   10045.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#dffAllLong.replace({'CountyID': SensorCountyDict})\nColumnCountyID.head()"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 18, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "CountyID    4453488\ndtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "ColumnCountyID.count()"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 19, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "CountyID    70272\ndtype: int64"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "ColumnCountyID.isna().sum()"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dffAllLong['Pollutant'] = dffAllLong.apply(lambda row: re.search('^.{8}(.*)_', row['SensorPollID']).group(1), axis=1)"
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dffAllLong['CountyID'] = ColumnCountyID['CountyID']"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dffAllLong = dffAllLong.dropna().drop(['observation_period','SensorPollID'], axis=1)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 23, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "PollutantConc    22.141\nPollutant            NO\nCountyID          14626\nName: 906123, dtype: object"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "dffAllLong.iloc[888555]"
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 26, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PollutantConc</th>\n      <th>Pollutant</th>\n      <th>CountyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4523755</th>\n      <td>91.521347</td>\n      <td>NOx</td>\n      <td>16064</td>\n    </tr>\n    <tr>\n      <th>4523756</th>\n      <td>68.096954</td>\n      <td>NOx</td>\n      <td>16064</td>\n    </tr>\n    <tr>\n      <th>4523757</th>\n      <td>113.357315</td>\n      <td>NOx</td>\n      <td>16064</td>\n    </tr>\n    <tr>\n      <th>4523758</th>\n      <td>88.717621</td>\n      <td>NOx</td>\n      <td>16064</td>\n    </tr>\n    <tr>\n      <th>4523759</th>\n      <td>59.788193</td>\n      <td>NOx</td>\n      <td>16064</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "         PollutantConc Pollutant  CountyID\n4523755      91.521347       NOx     16064\n4523756      68.096954       NOx     16064\n4523757     113.357315       NOx     16064\n4523758      88.717621       NOx     16064\n4523759      59.788193       NOx     16064"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "dffAllLong['CountyID'] = dffAllLong['CountyID'].astype('int64')\ndffAllLong.tail()"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Memory usage:  135.90966796875  MB\n"
                }
            ], 
            "source": "print(\"Memory usage: \", (dffAllLong.memory_usage(index=True).sum()/1048576.0), \" MB\")"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SensorID</th>\n      <th>SensorTown</th>\n      <th>CountyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>644</th>\n      <td>DESL002</td>\n      <td>Bexbach</td>\n      <td>10045</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "    SensorID SensorTown  CountyID\n644  DESL002    Bexbach     10045"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "SensorLocation.loc[SensorLocation['SensorID']=='DESL002']"
        }, 
        {
            "source": "### Saving \"Long\" DataFrame to COS\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "dffAllLongSpark = spark.createDataFrame(dffAllLong)\ndffAllLongSpark.write.parquet(cos.url('dffAllLong.parquet', 'capstone-donotdelete-pr-zpykcz8f0kxuad'))"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}